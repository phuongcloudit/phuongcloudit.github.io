<!DOCTYPE html><title>Advanced Web scraping and crawling with Scrapy and SQLAlchemy - manhhomienbienthuy's space</title> <meta charset=utf-8> <meta name=viewport content="width=device-width, initial-scale=1"> <link rel=apple-touch-icon href=/theme/images/icon-touch.png> <link rel=icon sizes=192x192 href=/theme/images/icon-touch.png> <link rel="shortcut icon" href=/theme/images/favicon.ico> <link rel=author href=/humans.txt> <meta name=msapplication-TileImage content=/theme/images/icon-tile.png> <meta name=twitter:dnt content=on> <meta name=Author content=manhhomienbienthuy> <meta name=rating content=general> <meta name=twitter:card content=product> <meta name=twitter:site content=@_naa_4f> <meta name=twitter:creator content=@_naa_4f> <link href=/feeds/all.atom.xml type=application/atom+xml rel=alternate title="manhhomienbienthuy's space Full Atom Feed"> <meta name=description content="Trong bài viết trước tôi đã giới thiệu kỹ thuật cơ bản sử dụng Scrapy và SQLAlchemy để scraping và crawling dữ liệu từ trang StackOverflow. Trong bài viết này, tôi sẽ giới thiệu một sỗ kỹ thuật nâng cao sử dụng Scrapy để scraping và crawling Web như follow …"> <meta name=keywords content="Python, Scrapy, SQLAlchemy, scraping, crawling, blog, naa, manhhomienbienthuy, pelican, static site generator"> <meta name=twitter:title content="Advanced Web scraping and crawling with Scrapy and SQLAlchemy - manhhomienbienthuy's space"> <meta name=twitter:description content="Trong bài viết trước tôi đã giới thiệu kỹ thuật cơ bản sử dụng Scrapy và SQLAlchemy để scraping và crawling dữ liệu từ trang StackOverflow. Trong bài viết này, tôi sẽ giới thiệu một sỗ kỹ thuật nâng cao sử dụng Scrapy để scraping và crawling Web như follow …"> <meta name=twitter:image content=/https://i.imgur.com/JJBQZrk.png> <link rel=stylesheet href=//cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css> <link rel=stylesheet href=//maxcdn.bootstrapcdn.com/font-awesome/4.0.0/css/font-awesome.min.css> <link rel=stylesheet href=/theme/css/vpyeu.min.css?5d2c7d5e> <header> <div class=navbar> <div class=wrapper> <div class=nav-menu> <div class=menu-toggle> <i class="fa fa-reorder"></i> </div> <ul class=menus> <li><a href=/ >Home</a> <li><a href=/category/general.html> General <li><a href=/category/life.html> Life <li><a href=/category/programming.html class=current> Programming <li><a href=/category/travel.html> Travel </ul> </div><div class="right links"> <ul> <li> <a href=https://twitter.com/_naa_4f target=_blank> <i class="fa fa-twitter"></i> </a> <li> <a href=https://instagram.com/manhhomienbienthuy/ target=_blank> <i class="fa fa-instagram"></i> </a> <li> <a href=https://www.facebook.com/manhhomienbienthuy target=_blank> <i class="fa fa-facebook"></i> </a> <li> <a href=https://github.com/manhhomienbienthuy target=_blank> <i class="fa fa-github"></i> </a> <li> <a href=/feeds/all.atom.xml target=_blank> <i class="fa fa-rss"></i> </a> </ul> </div> </div> </div><noscript> <div class="warning head-warn"> <div class=wrapper> <p><strong>Notice:</strong> While JavaScript is not essential for this website, your interaction with the content will be limited. Please turn JavaScript on for the full experience. </div> </div> </noscript><div class=banner> <div class=wrapper> <a href=/ > <img alt="manhhomienbienthuy's space" src=/theme/images/logo.png> </a> </div> </div></header> <main> <div class=wrapper> <div class=main-wrapper> <div class=entry> <div class=entry-detail> <div class=post> <h1 class=title> Advanced Web scraping and crawling with Scrapy and SQLAlchemy </h1> <div class=meta> Posted in <a href=/category/programming.html>Programming</a> on January 11, 2016 by <a href=/pages/about-me.html>manhhomienbienthuy</a> <span class=right> <i class="fa fa-comments"></i> <a href=#disqus_thread data-disqus-identifier=/2016/Jan/11/advanced-web-scraping-and-crawling-with-scrapy-and-sqlalchemy.html> Comments </a> </span> </div> <div class=post-body> <img src=https://i.imgur.com/JJBQZrk.png alt="Advanced Web scraping and crawling with Scrapy and SQLAlchemy"> <p>Trong <a href=../../../2015/Dec/11/web-scraping-and-crawling-with-scrapy-and-sqlalchemy.html>bài viết trước</a> tôi đã giới thiệu kỹ thuật cơ bản sử dụng Scrapy và SQLAlchemy để scraping và crawling dữ liệu từ trang <a href=http://stackoverflow.com/ >StackOverflow</a>. Trong bài viết này, tôi sẽ giới thiệu một sỗ kỹ thuật nâng cao sử dụng Scrapy để scraping và crawling Web như follow link, crawl qua các trang dựa vào link ở cuối trang, gửi request để lấy dữ liệu từ các trang view câu hỏi...</p> <blockquote> <p>Bài viết này trình bày các kỹ thuật nâng cao với Scrapy nên bạn cần biết cách sử dụng Scrapy về cơ bản. Ngoài ra, nhiều đoạn code được tái sử dụng từ bài viết trước, nên tôi recommend bạn nên đọc qua bài viết đó nếu bạn chưa đọc.</p> </blockquote> <h1 id=y-tuong>Ý tưởng<a class=headerlink href=#y-tuong title="Permanent link">&para;</a></h1> <p>Có nhiều cách để thực hiện việc này, chúng ta có thể mở rộng Spider đang có, gửi thêm 1 request đến trang kế tiếp bằng cách sử dụng link ở cuối trang cũ, sau đó <code>yield</code> một <code>Request</code> tới trang này, sử dụng callback tới chính hàm <code>parse</code> và thực hiện việc lấy dữ liệu với các trang tiếp theo giống hệt như trang ban đầu. Scrapy sẽ tự động gửi request tới link mà chúng ta chỉ định. Bạn có thể nghiên cứu thêm các thông tin khác về việc này ở <a href=http://doc.scrapy.org/en/latest/topics/spiders.html>tài liệu của Scrapy</a>.</p> <p>Có một cách khác, đơn giản hơn, đó là sử dụng <a href=http://doc.scrapy.org/en/latest/topics/spiders.html#crawlspider>CrawlSpider</a> có sẵn của Scrapy. Đây là một spider phiên bản mở rộng của Spider thông thường, được thiết kế để sử dụng trong trường hợp mà chúng ta đang cần - crawl dữ liệu được phân trang.</p> <h1 id=crawlspider>CrawlSpider<a class=headerlink href=#crawlspider title="Permanent link">&para;</a></h1> <p>Bây giờ, chúng ta cần xây dựng một Spider kế thừa từ CrawlSpider. Có nhiều cách để thực hiện việc này.</p> <h2 id=su-dung-mau-co-san>Sử dụng mẫu có sẵn<a class=headerlink href=#su-dung-mau-co-san title="Permanent link">&para;</a></h2> <p>Scrapy có một công cụ để <a href=http://doc.scrapy.org/en/latest/topics/commands.html#std:command-genspider>sinh code tự động cho các spider</a>. Chúng ta có thể sử dụng lệnh như sau:</p> <div class=codehilite><pre><span></span><span class=gp>$</span> scrapy genspider stack_crawler stackoverflow.com -t crawl
<span class=go>Created spider &#39;stack_crawler&#39; using template &#39;crawl&#39; in module:</span>
<span class=go>  stack.spiders.stack_crawler</span>
</pre></div> <p>Lệnh trên sẽ thêm một spider mới trong thư mục <code>spiders</code> đang có. Tuy nhiên, đây không phải là cách duy nhất. Mẫu có sẵn có rất nhiều code được sinh tự động, mà như thế rất dễ khiến chúng ta lười đi. Nên tôi sẽ sửa lại spider đang có để phù hợp với nhu cầu.</p> <h2 id=sua-lai-spider-ang-co>Sửa lại spider đang có<a class=headerlink href=#sua-lai-spider-ang-co title="Permanent link">&para;</a></h2> <p>Thực ra cũng rất đơn giản, chúng ta cần update class <code>StackSpider</code> kế thừa từ class <code>CrawlSpider</code> thay vì class <code>Spider</code> thông thường</p> <div class=codehilite><pre><span></span><span class=kn>from</span> <span class=nn>scrapy.spiders</span> <span class=kn>import</span> <span class=n>CrawlSpider</span>

<span class=k>class</span> <span class=nc>StackSpider</span><span class=p>(</span><span class=n>CrawlSpider</span><span class=p>):</span>
    <span class=o>...</span>
</pre></div> <h2 id=them-rule>Thêm rule<a class=headerlink href=#them-rule title="Permanent link">&para;</a></h2> <p>Chúng ta cần thêm rule để Scrapy biết cách tìm link trang kế tiếp và request đến trang đó. Việc này cũng rất dễ dàng bằng cách thêm một regular expression vào thuộc tính <code>rules</code> của class:</p> <div class=codehilite><pre><span></span><span class=kn>from</span> <span class=nn>scrapy.linkextractors</span> <span class=kn>import</span> <span class=n>LinkExtractor</span>
<span class=kn>from</span> <span class=nn>scrapy.spiders</span> <span class=kn>import</span> <span class=n>CrawlSpider</span><span class=p>,</span> <span class=n>Rule</span>

<span class=k>class</span> <span class=nc>StackSpider</span><span class=p>(</span><span class=n>CrawlSpider</span><span class=p>):</span>
    <span class=o>...</span>
    <span class=n>rules</span> <span class=o>=</span> <span class=p>(</span>
        <span class=n>Rule</span><span class=p>(</span><span class=n>LinkExtractor</span><span class=p>(</span><span class=n>allow</span><span class=o>=</span><span class=sa>r</span><span class=s2>&quot;questions\?page=[0-5]&amp;sort=newest&quot;</span><span class=p>),</span>
             <span class=n>callback</span><span class=o>=</span><span class=s2>&quot;parse_item&quot;</span><span class=p>,</span> <span class=n>follow</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span>
    <span class=p>)</span>
</pre></div> <blockquote> <p>Ví dụ trên, tôi chỉ scrape dữ liệu ở 5 trang. Bạn có thể điều chỉnh nó để phù hợp với nhu cầu của riêng mình.</p> </blockquote> <p>Sau đó bạn cần đổi tên phương thức <code>parse</code> thành <code>parse_item</code>. Bây giờ, Scrapy sẽ tự động tìm link các trang kế tiếp và gửi request đến trang đó, sau đó Scrapy sẽ xử lý dữ liệu thu về bằng phương thức <code>parse_item</code>. Nội dung phương thức <code>parse</code> đã viết trước đó không cần thay đổi gì, bởi các trang cấu trúc giống hệt nhau.</p> <blockquote> <p>Tại sao phải đổi tên phương thức <code>parse</code> thành <code>parse_item</code>? Bởi vì CrawlSpider đã có sẵn phương thức <code>parse</code> để thực hiện một số thao tác của nó, nếu bạn sử dụng phương thức <code>parse</code> nó sẽ ghi đè lên phương thức của CrawlSpider, khi đó, CrawlSpider không hoạt động đúng như thiết kế mà chỉ hoạt động như một Spider thông thường mà thôi.</p> </blockquote> <h2 id=them-thoi-gian-cho>Thêm thời gian chờ<a class=headerlink href=#them-thoi-gian-cho title="Permanent link">&para;</a></h2> <p>Có một điểm cần lưu ý, đó là bạn sẽ tăng áp lực phục vụ lên trang Web bạn đang muốn scrape bằng cách gửi request liên tục. Chúng ta không nên làm vậy. Vì vậy, chúng ta cần thiết lập <a href=http://doc.scrapy.org/en/latest/topics/settings.html#std:setting-DOWNLOAD_DELAY>thời gian chờ</a> khi download xong một trang. Việc này thực hiện rất dễ dàng bằng cách thêm dòng sau vào <code>settings.py</code></p> <div class=codehilite><pre><span></span><span class=n>DOWNLOAD_DELAY</span> <span class=o>=</span> <span class=mi>5</span>
</pre></div> <p>Thiết lập trên sẽ cho Scrapy khoảng thời gian chờ là 5 giây trước khi thực hiện request đến trang tiếp theo. Bạn có thể thay đổi cho phù hợp, tuy nhiên điều này rất quan trọng, bởi chúng ta không nên DDoS các dịch vụ như vậy (mặc dù khó thành công). Nếu bạn cố tình request liên tục đến trang StackOverflow, hãy cẩn thận vì bạn có thể bị ban IP.</p> <h1 id=scrape-noi-dung-cau-hoi>Scrape nội dung câu hỏi<a class=headerlink href=#scrape-noi-dung-cau-hoi title="Permanent link">&para;</a></h1> <p>Bây giờ, giả sử chúng ta muốn scrape thêm cả nội dung câu hỏi thay vì chỉ tiêu đề và URL. Điều này cũng không khó, bởi Scrapy hỗ trợ chúng ta rất tốt.</p> <p>Cách làm có thể mô tả ngắn gọn như sau: Từ trang danh sách các câu hỏi, chúng ta sẽ lấy được URL của chúng. Với mỗi URL này, chúng ta sẽ gửi một request đến nó và sẽ <code>yield</code> dữ liệu thu được khi xử lý những request này.</p> <h2 id=them-truong-content-cho-stackitem>Thêm trường content cho StackItem<a class=headerlink href=#them-truong-content-cho-stackitem title="Permanent link">&para;</a></h2> <p>Để chứa được nội dung câu hỏi, thì đối tượng StackItem phải có trường tương ứng, chúng ta sẽ thêm trường này.</p> <div class=codehilite><pre><span></span><span class=k>class</span> <span class=nc>StackItem</span><span class=p>(</span><span class=n>scrapy</span><span class=o>.</span><span class=n>Item</span><span class=p>):</span>
    <span class=o>...</span>
    <span class=n>content</span> <span class=o>=</span> <span class=n>scrapy</span><span class=o>.</span><span class=n>Field</span><span class=p>()</span>
</pre></div> <h2 id=lay-url-cua-cau-hoi-va-gui-request>Lấy URL của câu hỏi và gửi request<a class=headerlink href=#lay-url-cua-cau-hoi-va-gui-request title="Permanent link">&para;</a></h2> <p>Bây giờ, từ trang danh sách câu hỏi, chúng ta không lấy tiêu đề của câu hỏi nữa. Chúng ta chỉ lấy URL của chúng và gửi request đến những URL này và <code>yield</code> dữ liệu thu được.</p> <div class=codehilite><pre><span></span><span class=k>def</span> <span class=nf>parse_item</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
    <span class=n>questions</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//div[@class=&quot;summary&quot;]/h3&#39;</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>question</span> <span class=ow>in</span> <span class=n>questions</span><span class=p>:</span>
        <span class=n>question_location</span> <span class=o>=</span> <span class=n>question</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span>
            <span class=s1>&#39;a[@class=&quot;question-hyperlink&quot;]/@href&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>full_url</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>urljoin</span><span class=p>(</span><span class=n>question_location</span><span class=p>)</span>
        <span class=k>yield</span> <span class=n>scrapy</span><span class=o>.</span><span class=n>Request</span><span class=p>(</span><span class=n>full_url</span><span class=p>,</span> <span class=n>callback</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>parse_question</span><span class=p>)</span>
</pre></div> <p>Như vậy, với mỗi request đến từng câu hỏi, chúng ta sử dụng callback tới phương thức <code>parse_question</code> để xử lý dữ liệu. Trong phương thức này, chúng ta sẽ phân tích và tách ra những thông tin chúng ta cần.</p> <h2 id=phuong-thuc-parse_question>Phương thức <code>parse_question</code><a class=headerlink href=#phuong-thuc-parse_question title="Permanent link">&para;</a></h2> <p>Trong bài viết trước, tôi đã hướng dẫn cách sử dụng <a href=http://www.w3.org/TR/xpath/ >XPath selector</a> để chọn lọc ra các thông tin cần thiết. Tuy nhiên, XPath có một nhược điểm, đó nếu đối tượng có nhiều thành phần con trong nó thì rất khó để trích xuất dữ liệu. Trong thường hợp này, chúng ta có thể sử dụng <a href=http://www.w3.org/TR/selectors/ >CSS selector</a>.</p> <p>Nếu là một người lập trình Web thì chắc chắn bạn sẽ không xa lạ gì với CSS selector. Tuy nhiên, bạn có thể tham khảo thêm về <a href=http://doc.scrapy.org/en/latest/topics/selectors.html#selectors>selector của Scrapy</a> để biết cách sử dụng sao cho đúng. Vì selector dùng trong các file CSS có chút khác biệt nhỏ với selector của Scrapy.</p> <p>Bạn có thể sử dụng Chrome để hộ trợ làm việc với CSS selector. Cách làm cũng tương tự như với XPath.</p> <p><img alt="Chrome CSS Copy" src=https://i.imgur.com/liTkk5G.png></p> <p>Bây giờ, từ dữ liệu thu được, chúng ta cần trích xuất ra các thông tin như URL của câu hỏi, tiêu đề và nội dung câu hỏi đó.</p> <div class=codehilite><pre><span></span><span class=k>def</span> <span class=nf>parse_question</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
    <span class=n>item</span> <span class=o>=</span> <span class=n>StackItem</span><span class=p>()</span>
    <span class=n>item</span><span class=p>[</span><span class=s2>&quot;title&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>css</span><span class=p>(</span>
        <span class=s2>&quot;#question-header h1 a::text&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>extract</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
    <span class=n>item</span><span class=p>[</span><span class=s2>&quot;url&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>url</span>
    <span class=n>item</span><span class=p>[</span><span class=s2>&quot;content&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>css</span><span class=p>(</span>
        <span class=s2>&quot;.question .post-text&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>extract</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
    <span class=k>yield</span> <span class=n>item</span>
</pre></div> <p>Trong phương thức <code>parse_question</code> này, nếu muốn bạn vẫn có thể gửi request đến một trang khác nữa nếu bạn lấy được link từ trang này. Đây là một công cụ rất tiện ích của Scrapy cho phép chúng ta có thể follow các link dẫn từ hết trang này đến trang khác.</p> <h1 id=luu-du-lieu>Lưu dữ liệu<a class=headerlink href=#luu-du-lieu title="Permanent link">&para;</a></h1> <p>Còn một việc cần làm nữa là lưu dữ liệu thu được. Lúc trước chúng ta chỉ lưu URL và tiêu đề của câu hỏi, bây giờ chúng ta cần thêm 1 trường lưu nội dung câu hỏi đó.</p> <div class=codehilite><pre><span></span><span class=n>_stack_items</span> <span class=o>=</span> <span class=n>Table</span><span class=p>(</span><span class=s2>&quot;questions&quot;</span><span class=p>,</span> <span class=n>_metadata</span><span class=p>,</span>
                     <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;id&quot;</span><span class=p>,</span> <span class=n>Integer</span><span class=p>,</span> <span class=n>primary_key</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span>
                     <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;url&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>),</span>
                     <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;title&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>),</span>
                     <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;content&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>))</span>
</pre></div> <blockquote> <p>Lưu ý rằng, việc này chỉ có tác dụng khai báo với SQLAlchemy biết rằng chúng ta sẽ lưu thêm 1 trường <code>content</code> nữa. Mặc dù pipelines đã được thiết kế để tạo bảng nếu bảng đó chưa tồn tại, nhưng nếu bảng đã tồn tại rồi thì nó sẽ không thay đổi cấu trúc nữa. Bảng lần trước chỉ có 2 trường là <code>url</code> và <code>title</code>. Bạn sẽ phải thêm trường <code>content</code> bằng tay vào bảng này, hoặc bạn có thể xóa bảng đi để pipelines tạo bảng mới cho bạn.</p> </blockquote> <p>Bây giờ, dữ liệu chúng ta thu được là rất lớn, vì scrape trên 5 trang. Nên mỗi lần scrape có thể sẽ có những dữ liệu bị lặp lại. Nên khi lưu vào cơ sở dữ liệu, chúng ta cần kiểm tra xem dữ liệu đã được ghi trong bảng chưa. Nếu đã có dữ liệu rồi thì không cần thêm bản ghi mới nữa.</p> <div class=codehilite><pre><span></span><span class=k>def</span> <span class=nf>process_item</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>item</span><span class=p>,</span> <span class=n>spider</span><span class=p>):</span>
    <span class=n>is_valid</span> <span class=o>=</span> <span class=bp>True</span>
    <span class=k>for</span> <span class=n>data</span> <span class=ow>in</span> <span class=n>item</span><span class=p>:</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>data</span><span class=p>:</span>
            <span class=n>is_valid</span> <span class=o>=</span> <span class=bp>False</span>
            <span class=k>raise</span> <span class=n>DropItem</span><span class=p>(</span><span class=s2>&quot;Missing </span><span class=si>%s</span><span class=s2>!&quot;</span> <span class=o>%</span> <span class=n>data</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>is_valid</span><span class=p>:</span>
        <span class=n>q</span> <span class=o>=</span> <span class=n>select</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>stack_items</span><span class=p>])</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>stack_items</span><span class=o>.</span><span class=n>c</span><span class=o>.</span><span class=n>title</span> <span class=o>==</span>
                                             <span class=n>item</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>])</span>
        <span class=n>existence</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>connection</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>q</span><span class=p>))</span>
        <span class=k>if</span> <span class=n>existence</span><span class=p>:</span>
            <span class=k>raise</span> <span class=n>DropItem</span><span class=p>(</span><span class=s2>&quot;Item existed&quot;</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>ins_query</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>stack_items</span><span class=o>.</span><span class=n>insert</span><span class=p>()</span><span class=o>.</span><span class=n>values</span><span class=p>(</span>
                <span class=n>url</span><span class=o>=</span><span class=n>item</span><span class=p>[</span><span class=s2>&quot;url&quot;</span><span class=p>],</span>
                <span class=n>title</span><span class=o>=</span><span class=n>item</span><span class=p>[</span><span class=s2>&quot;title&quot;</span><span class=p>],</span>
                <span class=n>content</span><span class=o>=</span><span class=n>item</span><span class=p>[</span><span class=s2>&quot;content&quot;</span><span class=p>]</span>
            <span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>connection</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>ins_query</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>item</span>
</pre></div> <h1 id=test>Test<a class=headerlink href=#test title="Permanent link">&para;</a></h1> <p>Bạn có thể test công cụ sau khi thay đổi</p> <div class=codehilite><pre><span></span><span class=gp>$</span> scrapy crawl stack
</pre></div> <p>Và kết quả là dữ liệu đã được thu về rất đầy đủ.</p> <p><img alt="Crawled data" src=https://i.imgur.com/0Hy7rTF.png></p> <h1 id=ket-luan>Kết luận<a class=headerlink href=#ket-luan title="Permanent link">&para;</a></h1> <p>Bạn có thể tham khảo mã nguồn ở <a href=https://github.com/manhhomienbienthuy/crawl-sample>ví dụ của tôi trên Github</a>. Hoặc bạn có thể tự xây dựng công cụ cho mình. Scrapy là một thư viện rất tuyệt vời, và nó cung cấp tất cả những công cụ chúng ta cần để thực hiện việc scrape và crawl dữ liệu.</p> </div> <div class=post-footer> <div class=tags> <i class="fa fa-tags"></i> <span>#Python</span> <span>#Scrapy</span> <span>#SQLAlchemy</span> <span>#scraping</span> <span>#crawling</span> </div> </div> </div><div class=blog-pager> <span class=newer-link> <a href=/2016/Jan/24/how-to-use-django-admin-and-when-should-not-use-it.html> Newer Post </a> </span> <span class=older-link> <a href=/2016/Jan/05/python-iterator-generator.html> Older Post </a> </span> </div><div class=comments> <div class=finally> <p><em>I apologise for any typos. If you notice a problem, please let me know.</em> <p>Thank you all for your attention. </div> <div id=disqus_thread></div> <script src=/theme/js/disqus.min.js?81e8a5f5></script> <noscript> Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript> comments powered by Disqus. </a> </noscript> </div></div> </div> </div> <div class=sidebar-wrapper> <div class=widget> <h2>Welcome</h2> <div> <img src=/theme/images/banner.gif alt=Welcome> </div> </div><div class="widget recent-posts"> <h2>Recent Posts</h2> <ul> <li> <a href=/2019/May/20/elasticsearch-data-organization.html> <img alt="Elasticsearch: Data organization" src=https://i.imgur.com/JT4y7Qf.jpg> </a> <a href=/2019/May/20/elasticsearch-data-organization.html>Elasticsearch: Data organization</a> <li> <a href=/2019/May/20/elasticsearch-intro.html> <img alt="Elasticsearch: Intro" src=https://i.imgur.com/JT4y7Qf.jpg> </a> <a href=/2019/May/20/elasticsearch-intro.html>Elasticsearch: Intro</a> <li> <a href=/2019/Apr/20/javascript-popups.html> <img alt="JavaScript: Popups" src=https://i.imgur.com/FxmcwPy.png> </a> <a href=/2019/Apr/20/javascript-popups.html>JavaScript: Popups</a> <li> <a href=/2019/Mar/20/javascript-iterator-and-generator.html> <img alt="JavaScript: Iterator and generator" src=https://i.imgur.com/lev8iT9.jpg> </a> <a href=/2019/Mar/20/javascript-iterator-and-generator.html>JavaScript: Iterator and generator</a> <li> <a href=/2019/Feb/20/javascript-decorator.html> <img alt="JavaScript decorator" src=https://i.imgur.com/Sh3yLI0.png> </a> <a href=/2019/Feb/20/javascript-decorator.html>JavaScript decorator</a> </ul> </div><div class="widget labels"> <h2>Blog Archive</h2> <ul> <li> <a href=/2019/ > 2019 </a> <li> <a href=/2018/ > 2018 </a> <li> <a href=/2017/ > 2017 </a> <li> <a href=/2016/ > 2016 </a> <li> <a href=/2015/ > 2015 </a> <li> <a href=/2014/ > 2014 </a> <li> <a href=/2013/ > 2013 </a> <li> <a href=/2012/ > 2012 </a> <li> <a href=/2011/ > 2011 </a> <li> <a href=/2010/ > 2010 </a> </ul> </div><div class=widget> <h2>Twitter timeline</h2> <a class=twitter-timeline data-height=500 data-dnt=true data-theme=light href=https://twitter.com/_naa_4f data-chrome="noheader nofooter transparent noborders"> Tweets by manhhomienbienthuy </a> </div> </div> </div> <a href=# class="smooth-scroll back-to-top"> <i class="fa fa-arrow-circle-up fa-3x"></i> </a> </main> <footer> <div class=infos> <div class=wrapper> <div class=widget> <a href=/ title="manhhomienbienthuy's space" class=logo> <img alt="manhhomienbienthuy's space" src=/theme/images/logo_white.png> </a> <span class=right>I'm a hacker, enter my world...</span> </div><div class=widget> <p> Created with all my ♥ and soul, dedicated to my love, yunachan <p> Powered by <a href=http://blog.getpelican.com/ target=_blank>Pelican</a>, which takes great advantage of <a href=https://www.python.org/ target=_blank>Python</a> <p> This site content is licensed under a <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank> CC BY-NC-ND 4.0 </a> License. <p> Updated at <a target=_blank href="http://www.timeanddate.com/worldclock/fixedtime.html?iso=2019-06-20T02:42:55"> 2019-06-20 02:42:55 </a> </div><div class=widget> <p> Hosting by <a href=https://manhhomienbienthuy.bitbucket.io/ >Bitbucket</a> and <a href=https://manhhomienbienthuy.github.io/ >Github</a>, image hosting by <a href=https://manhhomienbienthuy.imgur.com/ target=_blank>imgur</a>, <a href=https://instagram.com/manhhomienbienthuy/ target=_blank>Instagram</a> and <a href=https://photos.google.com/ target=_blank>Google Photo</a> <p> Theme based on <a href=https://vanice-veethemes.blogspot.com/ target=_blank>Vanice theme</a>, icons from <a href=https://fontawesome.com/ target=_blank>Font Awesome</a>, comments powered by <a href=https://disqus.com/home/forums/manhhomienbienthuy/ target=_blank>Disqus</a> </div> </div> </div> <div class=credits> <div class=wrapper> <div class=left> <!--
          Regarding copyright, in general, standalone pages (as
          opposed to files generated as part of manuals) on the GNU
          web server should be under CC BY-ND 4.0.  Please do NOT
          change or remove this without talking with the webmasters or
          licensing team first.  Please make sure the copyright date
          is consistent with the document.  For web pages, it is ok to
          list just the latest year the document was modified, or
          published.

          If you wish to list earlier years, that is ok too.  Either
          "2001, 2002, 2003" or "2001-2003" are ok for specifying
          years, as long as each year in the range is in fact a
          copyrightable year, i.e., a year in which the document was
          published (including being publicly visible on the web or in
          a revision control system).
        --> Copyright © 2010-2019 <a href=/pages/about-me.html><strong>manhhomienbienthuy</strong></a>. All rights reserved. </div> <div class=right> <ul> <li><a href=/ >Home</a> <li><a href=/pages/about-me.html>About</a> <li><a href=# class=smooth-scroll>Top ↑</a> </ul> </div> </div> </div></footer> <script src=https://code.jquery.com/jquery-3.2.1.js></script> <script src=//cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js></script> <script src=//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js></script> <script src=/theme/js/vpyeu.min.js?d72c87bd></script> <script id=dsq-count-scr src=https://manhhomienbienthuy.disqus.com/count.js async></script>