<!DOCTYPE html><title>Web scraping and crawling with Scrapy and SQLAlchemy - manhhomienbienthuy's space</title> <meta charset=utf-8> <meta name=viewport content="width=device-width, initial-scale=1"> <link rel=apple-touch-icon href=/theme/images/icon-touch.png> <link rel=icon sizes=192x192 href=/theme/images/icon-touch.png> <link rel="shortcut icon" href=/theme/images/favicon.ico> <link rel=author href=/humans.txt> <meta name=msapplication-TileImage content=/theme/images/icon-tile.png> <meta name=twitter:dnt content=on> <meta name=Author content=manhhomienbienthuy> <meta name=rating content=general> <meta name=twitter:card content=product> <meta name=twitter:site content=@_naa_4f> <meta name=twitter:creator content=@_naa_4f> <link href=/feeds/all.atom.xml type=application/atom+xml rel=alternate title="manhhomienbienthuy's space Full Atom Feed"> <meta name=description content="Trong bài viết này, tôi sẽ giới thiệu cách xây dựng một công cụ scraping và crawling Web. Dữ liệu sẽ được thu về từ Stack Overflow và chúng ta sẽ trích xuất những câu hỏi mới nhất (Tiêu đề và URL). Dữ liệu thu được sẽ được lưu vào …"> <meta name=keywords content="Python, Scrapy, SQLAlchemy, scraping, crawling, blog, naa, manhhomienbienthuy, pelican, static site generator"> <meta name=twitter:title content="Web scraping and crawling with Scrapy and SQLAlchemy - manhhomienbienthuy's space"> <meta name=twitter:description content="Trong bài viết này, tôi sẽ giới thiệu cách xây dựng một công cụ scraping và crawling Web. Dữ liệu sẽ được thu về từ Stack Overflow và chúng ta sẽ trích xuất những câu hỏi mới nhất (Tiêu đề và URL). Dữ liệu thu được sẽ được lưu vào …"> <meta name=twitter:image content=/https://i.imgur.com/JJBQZrk.png> <link rel=stylesheet href=//cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css> <link rel=stylesheet href=//maxcdn.bootstrapcdn.com/font-awesome/4.0.0/css/font-awesome.min.css> <link rel=stylesheet href=/theme/css/vpyeu.min.css?5d2c7d5e> <header> <div class=navbar> <div class=wrapper> <div class=nav-menu> <div class=menu-toggle> <i class="fa fa-reorder"></i> </div> <ul class=menus> <li><a href=/ >Home</a> <li><a href=/category/general.html> General <li><a href=/category/life.html> Life <li><a href=/category/programming.html class=current> Programming <li><a href=/category/travel.html> Travel </ul> </div><div class="right links"> <ul> <li> <a href=https://twitter.com/_naa_4f target=_blank> <i class="fa fa-twitter"></i> </a> <li> <a href=https://instagram.com/manhhomienbienthuy/ target=_blank> <i class="fa fa-instagram"></i> </a> <li> <a href=https://www.facebook.com/manhhomienbienthuy target=_blank> <i class="fa fa-facebook"></i> </a> <li> <a href=https://github.com/manhhomienbienthuy target=_blank> <i class="fa fa-github"></i> </a> <li> <a href=/feeds/all.atom.xml target=_blank> <i class="fa fa-rss"></i> </a> </ul> </div> </div> </div><noscript> <div class="warning head-warn"> <div class=wrapper> <p><strong>Notice:</strong> While JavaScript is not essential for this website, your interaction with the content will be limited. Please turn JavaScript on for the full experience. </div> </div> </noscript><div class=banner> <div class=wrapper> <a href=/ > <img alt="manhhomienbienthuy's space" src=/theme/images/logo.png> </a> </div> </div></header> <main> <div class=wrapper> <div class=main-wrapper> <div class=entry> <div class=entry-detail> <div class=post> <h1 class=title> Web scraping and crawling with Scrapy and SQLAlchemy </h1> <div class=meta> Posted in <a href=/category/programming.html>Programming</a> on December 11, 2015 by <a href=/pages/about-me.html>manhhomienbienthuy</a> <span class=right> <i class="fa fa-comments"></i> <a href=#disqus_thread data-disqus-identifier=/2015/Dec/11/web-scraping-and-crawling-with-scrapy-and-sqlalchemy.html> Comments </a> </span> </div> <div class=post-body> <img src=https://i.imgur.com/JJBQZrk.png alt="Web scraping and crawling with Scrapy and SQLAlchemy"> <p>Trong bài viết này, tôi sẽ giới thiệu cách xây dựng một công cụ scraping và crawling Web. Dữ liệu sẽ được thu về từ <a href=http://stackoverflow.com/ >Stack Overflow</a> và chúng ta sẽ trích xuất những câu hỏi mới nhất (Tiêu đề và URL). Dữ liệu thu được sẽ được lưu vào cơ sở dữ liệu.</p> <blockquote> <p>Tôi viết bài này với mục đích lớn nhất là học hỏi một cách scrape và crawl Web bằng một thư viện của Python là Scrapy. Có thể Stack Overflow có API để làm những việc này, nhưng ở đây, nó không quan trọng. Khi làm việc thực tế thì bạn có thể chọn cách nào dễ dàng nhất cho mình. Còn trong bài viết này, chỉ đơn giản là học hỏi Scrapy mà thôi.</p> </blockquote> <h1 id=cai-at>Cài đặt<a class=headerlink href=#cai-at title="Permanent link">&para;</a></h1> <p>Chúng ta cần cài đặt <a href=http://scrapy.org/ >Scrapy</a> (v1.0.3) để scrape và <a href=http://www.sqlalchemy.org/ >SQLAlchemy</a> (v1.0.9) để lưu dữ liệu thu được vào cơ sở dữ liệu. Bạn cũng cần cài đặt máy chủ cơ sở dữ liệu trên máy tính của mình hoặc bạn có thể kết nối đến máy chủ từ xa thì càng tốt. Trong bài viết này, tôi sẽ không đi vào chi tiết việc cài đặt này. Tôi sẽ sử dụng <a href=https://www.sqlite.org/ >SQLite</a>, một hệ cơ sở dữ liệu khá đơn giản.</p> <blockquote> <p>Vào thời điểm bài viết này, Scrapy chưa hỗ trợ Python 3 nên chúng ta chỉ có thể làm việc với Python 2 mà thôi.</p> </blockquote> <h2 id=cai-at-scrapy>Cài đặt Scrapy<a class=headerlink href=#cai-at-scrapy title="Permanent link">&para;</a></h2> <p>Nếu sử dụng hệ điều hành họ Unix thì việc cài đặt rất dễ dàng, bạn có thể cài Scrapy bằng bất cứ trình quản lý package của Python nào. Ví dụ tôi sử dụng pip, tôi cài đặt với lệnh sau. Bạn cũng có thể cấu hình và sử dụng <a href=https://pypi.python.org/pypi/virtualenv>môi trường ảo của Python</a> để cài đặt các package làm việc trên đó.</p> <div class=codehilite><pre><span></span><span class=gp>$</span> pip install Scrapy
</pre></div> <p>Khi đã cài đặt Scrapy xong rồi thì bạn có thể kiểm tra lại bằng lệnh sau trong shell của Python:</p> <div class=codehilite><pre><span></span><span class=gp>&gt;&gt;&gt; </span><span class=kn>import</span> <span class=nn>scrapy</span>
<span class=go>&gt;&gt;&gt;</span>
</pre></div> <p>Nếu không có lỗi gì thì tức là chúng ta đã cài đặt Scrapy thành công.</p> <h2 id=sqlalchemy>SQLAlchemy<a class=headerlink href=#sqlalchemy title="Permanent link">&para;</a></h2> <p>Tiếp theo là cài đặt SQLAlchemy, ví dụ với pip bằng lệnh sau:</p> <div class=codehilite><pre><span></span><span class=gp>$</span> pip install SQLAlchemy
</pre></div> <p>Sau khi cài đặt Scrapy và SQLAlchemy là chúng ta đã sẵn sàng để xây dựng một chương trình scraping và crawling Web.</p> <h1 id=khoi-tao-project-voi-scrapy>Khởi tạo project với Scrapy<a class=headerlink href=#khoi-tao-project-voi-scrapy title="Permanent link">&para;</a></h1> <p>Khởi tạo một project với Scrapy bằng lệnh sau:</p> <div class=codehilite><pre><span></span><span class=gp>$</span> scrapy startproject stack
<span class=go>2015-12-10 14:43:54 [scrapy] INFO: Scrapy 1.0.3 started (bot: scrapybot)</span>
<span class=go>2015-12-10 14:43:54 [scrapy] INFO: Optional features available: ssl, http11</span>
<span class=go>2015-12-10 14:43:54 [scrapy] INFO: Overridden settings: {}</span>
<span class=go>New Scrapy project &#39;stack&#39; created in:</span>
<span class=go>    /home/naa/Works/python/crawl/stack</span>

<span class=go>You can start your first spider with:</span>
<span class=go>    cd stack</span>
<span class=go>    scrapy genspider example example.com</span>
</pre></div> <p>Lệnh này sẽ khởi tạo một project mới với đầy đủ các file cần thiết có cấu trúc như dưới đây.</p> <div class=codehilite><pre><span></span>├── scrapy.cfg
└── stack
    ├── __init__.py
    ├── items.py
    ├── pipelines.py
    ├── settings.py
    └── spiders
        └── __init__.py
</pre></div> <h2 id=ac-ta-du-lieu>Đặc tả dữ liệu<a class=headerlink href=#ac-ta-du-lieu title="Permanent link">&para;</a></h2> <p>File <code>items.py</code> được sử dụng để khai báo metadata cho những dữ liệu mà chúng ta muốn scrape. Trong file này có class <code>StackItem</code> là class được kế thừa từ class <a href=http://doc.scrapy.org/en/latest/topics/items.html><code>Item</code></a> của Scrapy. Trong class này đã định nghĩa trước một số đối tượng mà Scrapy cần dùng để scrape.</p> <div class=codehilite><pre><span></span><span class=kn>import</span> <span class=nn>scrapy</span>


<span class=k>class</span> <span class=nc>StackItem</span><span class=p>(</span><span class=n>scrapy</span><span class=o>.</span><span class=n>Item</span><span class=p>):</span>
    <span class=c1># define the fields for your item here like:</span>
    <span class=c1># name = scrapy.Field()</span>
    <span class=k>pass</span>
</pre></div> <p>Bây giờ, chúng ta sẽ thêm vào những dữ liệu mà chúng ta cần. Ví dụ, chúng ta cần tiêu đề và URL của các câu hỏi trên Stack Overflow, chúng ta sẽ định nghĩa trong file <code>items.py</code> như sau:</p> <div class=codehilite><pre><span></span><span class=kn>import</span> <span class=nn>scrapy</span>


<span class=k>class</span> <span class=nc>StackItem</span><span class=p>(</span><span class=n>scrapy</span><span class=o>.</span><span class=n>Item</span><span class=p>):</span>
    <span class=n>title</span> <span class=o>=</span> <span class=n>scrapy</span><span class=o>.</span><span class=n>Field</span><span class=p>()</span>
    <span class=n>url</span> <span class=o>=</span> <span class=n>scrapy</span><span class=o>.</span><span class=n>Field</span><span class=p>()</span>
</pre></div> <h2 id=tao-mot-spider>Tạo một Spider<a class=headerlink href=#tao-mot-spider title="Permanent link">&para;</a></h2> <p>Tạo một file tên là <code>stack_spider.py</code> trong thư mục <code>spiders</code> đã được tạo ở trên. Thư mục này khá đặc biệt, bởi nó là nơi chúng ta đưa ra các chỉ định cho Scrapy biết chính xác chúng ta muốn thu thập dữ liệu gì. Trong thư mục này, bạn có thể định nghĩa các Spider khác nhau cho các trang Web khác nhau.</p> <p>Bắt đầu bằng một class kế thừa từ class <code>Spider</code> của Scrapy và chúng ta sẽ thêm vào các thuộc tính cần thiết.</p> <div class=codehilite><pre><span></span><span class=kn>from</span> <span class=nn>scrapy</span> <span class=kn>import</span> <span class=n>Spider</span>


<span class=k>class</span> <span class=nc>StackSpider</span><span class=p>(</span><span class=n>Spider</span><span class=p>):</span>
    <span class=n>name</span> <span class=o>=</span> <span class=s2>&quot;stack&quot;</span>
    <span class=n>allowed_domains</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;stackoverflow.com&quot;</span><span class=p>]</span>
    <span class=n>start_urls</span> <span class=o>=</span> <span class=p>[</span>
        <span class=s2>&quot;http://stackoverflow.com/questions?pagesize=50&amp;sort=newest&quot;</span><span class=p>,</span>
    <span class=p>]</span>
</pre></div> <p>Những thuộc tính ở đây khá dễ hiểu, chúng thể hiện ý nghĩa qua chính tên của mình. Nếu cần thêm thông tin, bạn có thể tham khảo ở <a href=http://doc.scrapy.org/en/latest/topics/spiders.html>đây</a>:</p> <ul> <li><code>name</code> định nghĩa tên của Spider.</li> <li><code>allowed_domains</code> chứa URL gốc của trang Web bạn muốn scrape.</li> <li><code>start_urls</code> là danh sách các URL để Spider bắt đầu quá trình scraping. Tất cả mọi dữ liệu sẽ được Spider download từ các URL ở trong <code>start_urls</code> này.</li> </ul> <h2 id=xpath-selector>XPath selector<a class=headerlink href=#xpath-selector title="Permanent link">&para;</a></h2> <p>Một điều rất quan trọng, đó là <a href=http://doc.scrapy.org/en/latest/topics/selectors.html>Scrapy sử dụng XPath selector</a> để trích xuất dữ liệu từ các trang Web. Nói một cách khác, đó là chúng ta có thể chọn lọc ra một thành phần chính xác trên một trang Web bằng cách sử dụng <a href=http://www.w3.org/TR/xpath/ >XPath</a>.</p> <blockquote> <p>XPath is a language for selecting nodes in XML documents, which can also be used with HTML.</p> <ul> <li>Scrapy’s documentation -</li> </ul> </blockquote> <p>XPath khá là khó hiểu, nhưng rất may, trình duyệt Chrome với Developer Tools có hỗ trợ chúng ta làm việc với XPath. Chúng ta chỉ cần inspect một đối tượng trên trang Web, sau đó copy XPath của nó và chỉnh sửa nếu muốn.</p> <p><img alt="copy xpath in chrome" src=https://i.imgur.com/Wrj18xU.png></p> <p>Developer Tools của Chrome cũng cho phép chúng ta test thử XPath trên console của JavaScript, bằng cách sử dụng cú pháp <code>$x</code>, ví dụ như <code>$x("//img")</code>:</p> <p><img alt="test xpath in chrome" src=https://i.imgur.com/mUbonxF.png></p> <p>Bây giờ, chúng ta cần khai báo XPath của đối tượng mà chúng ta muốn trích xuất thông tin. Việc này cũng không khó lắm. Dùng Chrome vào Stack Overflow và chúng ta sẽ tìm XPath của chúng.</p> <p>Click phải chuột vào câu hỏi đầu tiên và chọn "Inspect Element"</p> <p><img alt="inspect element in chrome" src=https://i.imgur.com/lYB5Wds.png></p> <p>Bây giờ, chúng ta lấy XPath của phần tử đầu tiên <code>&lt;div class="summary"&gt;</code>, kết quả sẽ tương tự <code>//*[@id="question-summary-34194623"]/div[2]</code>. Chúng ta sẽ test trong JavaScript console.</p> <p><img alt="test xpath in chrome" src=https://i.imgur.com/xhAPLq1.png></p> <p>XPath lấy ra bằng cách trên chỉ lấy ra được 1 câu hỏi mà thôi. Cái chúng ta cần là lấy ra tất cả các câu hỏi. Điều này cũng rất đơn giản, chúng ta không sử dụng <code>id</code> mà sẽ sử dụng <code>class</code> cho XPath trên. Và XPath để lấy ra các câu hỏi sẽ là <code>//div[@class="summary"]/h3</code>. XPath này khá dễ hiểu, nó sẽ lấy ra tất cả các thành phần <code>&lt;h3&gt;</code> là con của một <code>&lt;div&gt;</code> có class là <code>summary</code>. Bạn có thể test lại XPath này trên Chrome.</p> <p><img alt="test chrome" src=https://i.imgur.com/5lL9101.png></p> <blockquote> <p>Chúng ta không sử dụng XPath copy từ Chrome bởi chúng chỉ lấy được 1 câu hỏi mà thôi. Trong phần lớn các trường hợp, chúng ta phải tự tìm 1 XPath phù hợp với mục địch của bạn. Tuy nhiên, nên dùng Chrome vì nó cho chúng ta giá trị ban đầu, từ đó chúng ta thay đổi thì dễ dàng hơn, trừ khi bạn là một pro có thể tự viết XPath cho mình.</p> </blockquote> <p>Bây giờ, chúng ta sẽ chỉnh sửa <code>stack_spider.py</code> để thêm vào XPath mà chúng ta muốn.</p> <div class=codehilite><pre><span></span><span class=kn>from</span> <span class=nn>scrapy</span> <span class=kn>import</span> <span class=n>Spider</span>
<span class=kn>from</span> <span class=nn>scrapy.selector</span> <span class=kn>import</span> <span class=n>Selector</span>


<span class=k>class</span> <span class=nc>StackSpider</span><span class=p>(</span><span class=n>Spider</span><span class=p>):</span>
    <span class=n>name</span> <span class=o>=</span> <span class=s2>&quot;stack&quot;</span>
    <span class=n>allowed_domains</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;stackoverflow.com&quot;</span><span class=p>]</span>
    <span class=n>start_urls</span> <span class=o>=</span> <span class=p>[</span>
        <span class=s2>&quot;http://stackoverflow.com/questions?pagesize=50&amp;sort=newest&quot;</span><span class=p>,</span>
    <span class=p>]</span>

    <span class=k>def</span> <span class=nf>parse</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
        <span class=n>questions</span> <span class=o>=</span> <span class=n>Selector</span><span class=p>(</span><span class=n>response</span><span class=p>)</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//div[@class=&quot;summary&quot;]/h3&#39;</span><span class=p>)</span>
</pre></div> <h2 id=trich-xuat-du-lieu>Trích xuất dữ liệu<a class=headerlink href=#trich-xuat-du-lieu title="Permanent link">&para;</a></h2> <p>Chúng ta vẫn cần phân tích và scrape các dữ liệu mà chúng ta muốn. Tất cả chúng đều ở trong <code>&lt;div class="summary"&gt;&lt;h3&gt;</code> và nhiệm vụ của chúng ta là lấy chúng ra. Bạn có thể update file <code>stack_spider.py</code> như sau:</p> <div class=codehilite><pre><span></span><span class=c1># -*- coding: utf-8 -*-</span>

<span class=kn>from</span> <span class=nn>scrapy</span> <span class=kn>import</span> <span class=n>Spider</span>
<span class=kn>from</span> <span class=nn>scrapy.selector</span> <span class=kn>import</span> <span class=n>Selector</span>

<span class=kn>from</span> <span class=nn>stack.items</span> <span class=kn>import</span> <span class=n>StackItem</span>


<span class=k>class</span> <span class=nc>StackSpider</span><span class=p>(</span><span class=n>Spider</span><span class=p>):</span>
    <span class=n>name</span> <span class=o>=</span> <span class=s2>&quot;stack&quot;</span>
    <span class=n>allowed_domains</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;stackoverflow.com&quot;</span><span class=p>]</span>
    <span class=n>start_urls</span> <span class=o>=</span> <span class=p>[</span>
        <span class=s2>&quot;http://stackoverflow.com/questions?pagesize=50&amp;sort=newest&quot;</span><span class=p>,</span>
    <span class=p>]</span>

    <span class=k>def</span> <span class=nf>parse</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>response</span><span class=p>):</span>
        <span class=n>questions</span> <span class=o>=</span> <span class=n>Selector</span><span class=p>(</span><span class=n>response</span><span class=p>)</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//div[@class=&quot;summary&quot;]/h3&#39;</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>question</span> <span class=ow>in</span> <span class=n>questions</span><span class=p>:</span>
            <span class=n>item</span> <span class=o>=</span> <span class=n>StackItem</span><span class=p>()</span>
            <span class=n>item</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>question</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span>
                <span class=s1>&#39;a[@class=&quot;question-hyperlink&quot;]/text()&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
            <span class=n>item</span><span class=p>[</span><span class=s1>&#39;url&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>question</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span>
                <span class=s1>&#39;a[@class=&quot;question-hyperlink&quot;]/@href&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>extract</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
            <span class=k>yield</span> <span class=n>item</span>
</pre></div> <p>Với đoạn code trên, chúng ta sẽ duyệt qua lần lượt các câu hỏi, và gán các giá trị <code>title</code> và <code>url</code> cho các <code>item</code> từ dữ liệu thu thập được. Bạn hãy chắc chắc các XPath ở trên là đúng bằng cách test thử với Developer Tools của Chrome. Các XPath cần test là <code>$x('//div[@class="summary"]/h3/a[@class="question-hyperlink"]/text()')</code> và <code>$x('//div[@class="summary"]/h3/a[@class="question-hyperlink"]/@href')</code>.</p> <h2 id=test>Test<a class=headerlink href=#test title="Permanent link">&para;</a></h2> <p>Sau khi xây dựng được công cụ scrape trên, chúng ta cần test nó. Việc test rất đơn giản, chúng ta chỉ cần chạy lệnh sau ở trong thư mục <code>stack</code>:</p> <div class=codehilite><pre><span></span><span class=gp>$</span> scrapy crawl stack
</pre></div> <p>Sau khi chạy lệnh trên, trên console sẽ hiển thị 50 câu hỏi với tiêu đề và URL của chúng. Bạn có thể ghi kết quả vào 1 file JSON với lệnh sau:</p> <div class=codehilite><pre><span></span><span class=gp>$</span> scrapy crawl stack -o items.json -t json
</pre></div> <p>Lệnh trên sẽ xuất kết quả ra 1 file <code>items.json</code>.</p> <p>Trên đây, chúng ta đã xây dựng công cụ scrape. Bây giờ, chúng ta cần lưu những dữ liệu thu được vào cơ sở dữ liệu với SQLAlchemy.</p> <h2 id=luu-du-lieu-vao-co-so-du-lieu-voi-sqlalchemy>Lưu dữ liệu vào cơ sở dữ liệu với SQLAlchemy<a class=headerlink href=#luu-du-lieu-vao-co-so-du-lieu-voi-sqlalchemy title="Permanent link">&para;</a></h2> <p>Mỗi lần thu thập được dữ liệu, chúng ta sẽ kiểm tra chúng và sau đó thêm chúng vào cơ sở dữ liệu.</p> <p>Trước hết, chúng ta cần khởi tạo một cơ sở dữ liệu để lưu trữ. Mở file <code>settings.py</code> và định nghĩa <a href=http://doc.scrapy.org/en/latest/topics/item-pipeline.html>pipeline</a> để lưu trữ như sau:</p> <div class=codehilite><pre><span></span><span class=n>ITEM_PIPELINES</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;stack.pipelines.StackPipeline&#39;</span><span class=p>,</span> <span class=p>]</span>
</pre></div> <h2 id=quan-ly-pipeline>Quản lý pipeline<a class=headerlink href=#quan-ly-pipeline title="Permanent link">&para;</a></h2> <p>Chúng ta đã xây dựng Spider để scrape và phân tích dữ liệu HTML. Bây giờ, chúng ta cần thiết lập cơ sở dữ liệu và kết nối chúng với nhau thông qua pipeline. Tất cả chúng được định nghĩa trong <code>pipelines.py</code>.</p> <h3 id=ket-noi-en-co-so-du-lieu>Kết nối đến cơ sở dữ liệu<a class=headerlink href=#ket-noi-en-co-so-du-lieu title="Permanent link">&para;</a></h3> <p>Chúng ta sẽ sử dụng SQLAlchemy để kết nối với cơ sở dữ liệu. Tôi sẽ sử dụng SQLite, tuy nghiên, SQLAlchemy hỗ trợ chúng ta kết nối đến rất nhiều cơ sở dữ liệu khác nhau như MySQL, PostgreSQL, v.v... bạn có thể dùng bất cứ hệ cơ sở dữ liệu nào mình muốn.</p> <p>Tôi đã từng giới thiệu cách <a href=../../../2015/Aug/30/web-development-with-cherrypy-and-jinja2.html>sử dụng SQLAlchemy làm ORM cho CherryPy</a>. Tuy nhiên, lần này, chúng ta không sử dụng SQLAlchemy làm ORM nữa mà sẽ sử dụng SQLAlchemy Core.</p> <div class=codehilite><pre><span></span><span class=kn>from</span> <span class=nn>sqlalchemy</span> <span class=kn>import</span> <span class=n>create_engine</span><span class=p>,</span> <span class=n>Table</span><span class=p>,</span> <span class=n>Column</span><span class=p>,</span> <span class=n>MetaData</span><span class=p>,</span> <span class=n>Integer</span><span class=p>,</span> <span class=n>Text</span>
<span class=kn>from</span> <span class=nn>scrapy.exceptions</span> <span class=kn>import</span> <span class=n>DropItem</span>


<span class=k>class</span> <span class=nc>StackPipeline</span><span class=p>(</span><span class=nb>object</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>_engine</span> <span class=o>=</span> <span class=n>create_engine</span><span class=p>(</span><span class=s2>&quot;sqlite:///data.db&quot;</span><span class=p>)</span>
        <span class=n>_connection</span> <span class=o>=</span> <span class=n>_engine</span><span class=o>.</span><span class=n>connect</span><span class=p>()</span>
        <span class=n>_metadata</span> <span class=o>=</span> <span class=n>MetaData</span><span class=p>()</span>
        <span class=n>_stack_items</span> <span class=o>=</span> <span class=n>Table</span><span class=p>(</span><span class=s2>&quot;questions&quot;</span><span class=p>,</span> <span class=n>_metadata</span><span class=p>,</span>
                             <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;id&quot;</span><span class=p>,</span> <span class=n>Integer</span><span class=p>,</span> <span class=n>primary_key</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span>
                             <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;url&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>),</span>
                             <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;title&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>))</span>
        <span class=n>_metadata</span><span class=o>.</span><span class=n>create_all</span><span class=p>(</span><span class=n>_engine</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>connection</span> <span class=o>=</span> <span class=n>_connection</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stack_items</span> <span class=o>=</span> <span class=n>_stack_items</span>
</pre></div> <p>Ở code trên, chúng ta tạo ra class <code>StackPipeline</code> và ở đó, chúng ta khởi tạo các đối tượng cần thiết và kết nối với cơ sở dữ liệu.</p> <h3 id=xu-ly-du-lieu>Xử lý dữ liệu<a class=headerlink href=#xu-ly-du-lieu title="Permanent link">&para;</a></h3> <p>Tiếp theo, chúng ta cần định nghĩa một phương thức để xử lý các dữ liệu thu về.</p> <div class=codehilite><pre><span></span><span class=kn>from</span> <span class=nn>sqlalchemy</span> <span class=kn>import</span> <span class=n>create_engine</span><span class=p>,</span> <span class=n>Table</span><span class=p>,</span> <span class=n>Column</span><span class=p>,</span> <span class=n>MetaData</span><span class=p>,</span> <span class=n>Integer</span><span class=p>,</span> <span class=n>Text</span>
<span class=kn>from</span> <span class=nn>scrapy.exceptions</span> <span class=kn>import</span> <span class=n>DropItem</span>


<span class=k>class</span> <span class=nc>StackPipeline</span><span class=p>(</span><span class=nb>object</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=n>_engine</span> <span class=o>=</span> <span class=n>create_engine</span><span class=p>(</span><span class=s2>&quot;sqlite:///data.db&quot;</span><span class=p>)</span>
        <span class=n>_connection</span> <span class=o>=</span> <span class=n>_engine</span><span class=o>.</span><span class=n>connect</span><span class=p>()</span>
        <span class=n>_metadata</span> <span class=o>=</span> <span class=n>MetaData</span><span class=p>()</span>
        <span class=n>_stack_items</span> <span class=o>=</span> <span class=n>Table</span><span class=p>(</span><span class=s2>&quot;questions&quot;</span><span class=p>,</span> <span class=n>_metadata</span><span class=p>,</span>
                             <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;id&quot;</span><span class=p>,</span> <span class=n>Integer</span><span class=p>,</span> <span class=n>primary_key</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span>
                             <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;url&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>),</span>
                             <span class=n>Column</span><span class=p>(</span><span class=s2>&quot;title&quot;</span><span class=p>,</span> <span class=n>Text</span><span class=p>))</span>
        <span class=n>_metadata</span><span class=o>.</span><span class=n>create_all</span><span class=p>(</span><span class=n>_engine</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>connection</span> <span class=o>=</span> <span class=n>_connection</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stack_items</span> <span class=o>=</span> <span class=n>_stack_items</span>

    <span class=k>def</span> <span class=nf>process_item</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>item</span><span class=p>,</span> <span class=n>spider</span><span class=p>):</span>
        <span class=n>is_valid</span> <span class=o>=</span> <span class=bp>True</span>
        <span class=k>for</span> <span class=n>data</span> <span class=ow>in</span> <span class=n>item</span><span class=p>:</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=n>data</span><span class=p>:</span>
                <span class=n>is_valid</span> <span class=o>=</span> <span class=bp>False</span>
                <span class=k>raise</span> <span class=n>DropItem</span><span class=p>(</span><span class=s2>&quot;Missing </span><span class=si>%s</span><span class=s2>!&quot;</span> <span class=o>%</span> <span class=n>data</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>is_valid</span><span class=p>:</span>
            <span class=n>ins_query</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>stack_items</span><span class=o>.</span><span class=n>insert</span><span class=p>()</span><span class=o>.</span><span class=n>values</span><span class=p>(</span>
                <span class=n>url</span><span class=o>=</span><span class=n>item</span><span class=p>[</span><span class=s2>&quot;url&quot;</span><span class=p>],</span> <span class=n>title</span><span class=o>=</span><span class=n>item</span><span class=p>[</span><span class=s2>&quot;title&quot;</span><span class=p>])</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>connection</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>ins_query</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>item</span>
</pre></div> <p>Ở đoạn code trên, phương thức này làm nhiệm vụ trích xuất dữ liệu, kết nối với cơ sở dữ liệu và ghi kết quả vào đó.</p> <h1 id=test_1>Test<a class=headerlink href=#test_1 title="Permanent link">&para;</a></h1> <p>Vậy là toàn bộ công cụ scrape và lưu dữ liệu đã hoàn thành, bây giờ chúng ta sẽ test thêm một lần nữa.</p> <div class=codehilite><pre><span></span><span class=gp>$</span> scrapy crawl stack
</pre></div> <p>Và kết quả là, chúng ta đã scrape và lưu kết quả thành công.</p> <p><img alt="crawled data" src=https://i.imgur.com/Dh5HIl9.png></p> <h1 id=ket-luan>Kết luận<a class=headerlink href=#ket-luan title="Permanent link">&para;</a></h1> <p>Trên đây là một ví dụ rất đơn giản. Chúng ta có thể dễ dàng scrape và crawl các trang Web bằng việc sử dụng Scrapy. Bạn có thể tự cài đặt và vận hành công cụ này, bởi nó cũng không quá khó. Bạn có thể tham khảo <a href=https://github.com/manhhomienbienthuy/crawl-sample>ví dụ của tôi trên Github</a> nếu thầy cần thiết.</p> </div> <div class=post-footer> <div class=tags> <i class="fa fa-tags"></i> <span>#Python</span> <span>#Scrapy</span> <span>#SQLAlchemy</span> <span>#scraping</span> <span>#crawling</span> </div> </div> </div><div class=blog-pager> <span class=newer-link> <a href=/2015/Dec/15/vim-and-python-a-match-made-in-heaven.html> Newer Post </a> </span> <span class=older-link> <a href=/2015/Dec/08/emacs-can-be-the-best-editor-for-python.html> Older Post </a> </span> </div><div class=comments> <div class=finally> <p><em>I apologise for any typos. If you notice a problem, please let me know.</em> <p>Thank you all for your attention. </div> <div id=disqus_thread></div> <script src=/theme/js/disqus.min.js?81e8a5f5></script> <noscript> Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript> comments powered by Disqus. </a> </noscript> </div></div> </div> </div> <div class=sidebar-wrapper> <div class=widget> <h2>Welcome</h2> <div> <img src=/theme/images/banner.gif alt=Welcome> </div> </div><div class="widget recent-posts"> <h2>Recent Posts</h2> <ul> <li> <a href=/2019/May/20/elasticsearch-data-organization.html> <img alt="Elasticsearch: Data organization" src=https://i.imgur.com/JT4y7Qf.jpg> </a> <a href=/2019/May/20/elasticsearch-data-organization.html>Elasticsearch: Data organization</a> <li> <a href=/2019/May/20/elasticsearch-intro.html> <img alt="Elasticsearch: Intro" src=https://i.imgur.com/JT4y7Qf.jpg> </a> <a href=/2019/May/20/elasticsearch-intro.html>Elasticsearch: Intro</a> <li> <a href=/2019/Apr/20/javascript-popups.html> <img alt="JavaScript: Popups" src=https://i.imgur.com/FxmcwPy.png> </a> <a href=/2019/Apr/20/javascript-popups.html>JavaScript: Popups</a> <li> <a href=/2019/Mar/20/javascript-iterator-and-generator.html> <img alt="JavaScript: Iterator and generator" src=https://i.imgur.com/lev8iT9.jpg> </a> <a href=/2019/Mar/20/javascript-iterator-and-generator.html>JavaScript: Iterator and generator</a> <li> <a href=/2019/Feb/20/javascript-decorator.html> <img alt="JavaScript decorator" src=https://i.imgur.com/Sh3yLI0.png> </a> <a href=/2019/Feb/20/javascript-decorator.html>JavaScript decorator</a> </ul> </div><div class="widget labels"> <h2>Blog Archive</h2> <ul> <li> <a href=/2019/ > 2019 </a> <li> <a href=/2018/ > 2018 </a> <li> <a href=/2017/ > 2017 </a> <li> <a href=/2016/ > 2016 </a> <li> <a href=/2015/ > 2015 </a> <li> <a href=/2014/ > 2014 </a> <li> <a href=/2013/ > 2013 </a> <li> <a href=/2012/ > 2012 </a> <li> <a href=/2011/ > 2011 </a> <li> <a href=/2010/ > 2010 </a> </ul> </div><div class=widget> <h2>Twitter timeline</h2> <a class=twitter-timeline data-height=500 data-dnt=true data-theme=light href=https://twitter.com/_naa_4f data-chrome="noheader nofooter transparent noborders"> Tweets by manhhomienbienthuy </a> </div> </div> </div> <a href=# class="smooth-scroll back-to-top"> <i class="fa fa-arrow-circle-up fa-3x"></i> </a> </main> <footer> <div class=infos> <div class=wrapper> <div class=widget> <a href=/ title="manhhomienbienthuy's space" class=logo> <img alt="manhhomienbienthuy's space" src=/theme/images/logo_white.png> </a> <span class=right>I'm a hacker, enter my world...</span> </div><div class=widget> <p> Created with all my ♥ and soul, dedicated to my love, yunachan <p> Powered by <a href=http://blog.getpelican.com/ target=_blank>Pelican</a>, which takes great advantage of <a href=https://www.python.org/ target=_blank>Python</a> <p> This site content is licensed under a <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank> CC BY-NC-ND 4.0 </a> License. <p> Updated at <a target=_blank href="http://www.timeanddate.com/worldclock/fixedtime.html?iso=2019-06-20T02:42:55"> 2019-06-20 02:42:55 </a> </div><div class=widget> <p> Hosting by <a href=https://manhhomienbienthuy.bitbucket.io/ >Bitbucket</a> and <a href=https://manhhomienbienthuy.github.io/ >Github</a>, image hosting by <a href=https://manhhomienbienthuy.imgur.com/ target=_blank>imgur</a>, <a href=https://instagram.com/manhhomienbienthuy/ target=_blank>Instagram</a> and <a href=https://photos.google.com/ target=_blank>Google Photo</a> <p> Theme based on <a href=https://vanice-veethemes.blogspot.com/ target=_blank>Vanice theme</a>, icons from <a href=https://fontawesome.com/ target=_blank>Font Awesome</a>, comments powered by <a href=https://disqus.com/home/forums/manhhomienbienthuy/ target=_blank>Disqus</a> </div> </div> </div> <div class=credits> <div class=wrapper> <div class=left> <!--
          Regarding copyright, in general, standalone pages (as
          opposed to files generated as part of manuals) on the GNU
          web server should be under CC BY-ND 4.0.  Please do NOT
          change or remove this without talking with the webmasters or
          licensing team first.  Please make sure the copyright date
          is consistent with the document.  For web pages, it is ok to
          list just the latest year the document was modified, or
          published.

          If you wish to list earlier years, that is ok too.  Either
          "2001, 2002, 2003" or "2001-2003" are ok for specifying
          years, as long as each year in the range is in fact a
          copyrightable year, i.e., a year in which the document was
          published (including being publicly visible on the web or in
          a revision control system).
        --> Copyright © 2010-2019 <a href=/pages/about-me.html><strong>manhhomienbienthuy</strong></a>. All rights reserved. </div> <div class=right> <ul> <li><a href=/ >Home</a> <li><a href=/pages/about-me.html>About</a> <li><a href=# class=smooth-scroll>Top ↑</a> </ul> </div> </div> </div></footer> <script src=https://code.jquery.com/jquery-3.2.1.js></script> <script src=//cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js></script> <script src=//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js></script> <script src=/theme/js/vpyeu.min.js?d72c87bd></script> <script id=dsq-count-scr src=https://manhhomienbienthuy.disqus.com/count.js async></script>